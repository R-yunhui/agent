# LangGraph ç»å…¸ Plan-and-Execute æ¨¡å¼
# ç‰¹ç‚¹ï¼šPlanner ä¸€æ¬¡æ€§åˆ¶å®šå®Œæ•´è®¡åˆ’ï¼ŒExecutor æ‰¹é‡æ‰§è¡Œï¼Œä¸é‡æ–°è§„åˆ’

import os
import time
import json
from typing import TypedDict, List, Annotated
import operator
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

load_dotenv()

# ==========================================
# 1. å®šä¹‰å·¥å…· (Mock)
# ==========================================

def video_search_tool(query: str):
    """æ£€ç´¢è§†é¢‘"""
    print(f"   ğŸ” è§†é¢‘æ£€ç´¢: {query}")
    time.sleep(0.3)
    return "Found video: VID_20240520_001"

def video_cv_analysis_tool(video_id: str, event_type: str = "general"):
    """CVåˆ†æ"""
    print(f"   ğŸ¥ CVåˆ†æ: {video_id}")
    time.sleep(0.5)
    if "å…¥ä¾µ" in event_type or "intrusion" in event_type:
        return "Detected: 2 Person Intrusion Events"
    return "Detected: 5 Cars, 2 Buses"

def video_llm_analysis_tool(video_id: str):
    """å¤§æ¨¡å‹åˆ†æ"""
    print(f"   ğŸ¤– LLMåˆ†æ: {video_id}")
    time.sleep(0.5)
    return "Summary: Busy street, traffic flowing smoothly"

def bi_analysis_tool(data: str):
    """BIåˆ†æ"""
    print(f"   ğŸ“Š BIç»Ÿè®¡")
    time.sleep(0.3)
    return "Stats: Intrusion Frequency = 2/day (High Risk)"

def report_generation_tool(context: str):
    """æŠ¥å‘Šç”Ÿæˆ"""
    print(f"   ğŸ“ ç”ŸæˆæŠ¥å‘Š")
    return f"Report Generated"

TOOL_MAP = {
    "video_search": video_search_tool,
    "cv_analysis": video_cv_analysis_tool,
    "llm_analysis": video_llm_analysis_tool,
    "bi_analysis": bi_analysis_tool,
    "report_generation": report_generation_tool
}

# ==========================================
# 2. å®šä¹‰çŠ¶æ€
# ==========================================

class Plan(BaseModel):
    """è®¡åˆ’æ¨¡å‹ï¼šä¸€æ¬¡æ€§ç”Ÿæˆå®Œæ•´çš„æ‰§è¡Œæ­¥éª¤"""
    steps: List[str] = Field(description="Complete list of tool names to execute. Available: video_search, cv_analysis, llm_analysis, bi_analysis, report_generation")
    reasoning: str = Field(description="Reasoning for this plan")

class AgentState(TypedDict):
    input: str
    plan: List[str]                                      # å®Œæ•´è®¡åˆ’åˆ—è¡¨
    past_steps: Annotated[List[str], operator.add]      # å·²æ‰§è¡Œçš„æ­¥éª¤è®°å½•
    final_response: str

# ==========================================
# 3. èŠ‚ç‚¹å®šä¹‰
# ==========================================

def planner_node(state: AgentState):
    """
    è§„åˆ’èŠ‚ç‚¹ï¼šä¸€æ¬¡æ€§åˆ¶å®šå®Œæ•´è®¡åˆ’
    å…³é”®ï¼šåªè°ƒç”¨ä¸€æ¬¡ï¼Œç„¶å Executor æ‰¹é‡æ‰§è¡Œ
    """
    print("\nğŸ§  [Planner] åˆ¶å®šå®Œæ•´æ‰§è¡Œè®¡åˆ’...")
    
    input_text = state["input"]
    
    llm = ChatOpenAI(
        model=os.getenv("OPENAI_CHAT_MODEL"),
        base_url=os.getenv("OPENAI_API_BASE_URL"),
        api_key=os.getenv("OPENAI_API_KEY"),
        temperature=0
    )
    
    system_prompt = """ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ä»»åŠ¡è§„åˆ’å‘˜ã€‚æ ¹æ®ç”¨æˆ·è¯·æ±‚ï¼Œä¸€æ¬¡æ€§åˆ¶å®šå®Œæ•´çš„æ‰§è¡Œè®¡åˆ’ã€‚

å¯ç”¨å·¥å…·ï¼š
1. video_search: æŸ¥æ‰¾è§†é¢‘ï¼ˆå¿…é¡»å…ˆæ‰§è¡Œï¼‰
2. cv_analysis: è§†è§‰åˆ†æï¼ˆæ£€æµ‹ç‰©ä½“ã€å…¥ä¾µäº‹ä»¶ç­‰ï¼‰
3. llm_analysis: å†…å®¹ç†è§£ï¼ˆæ€»ç»“ã€æè¿°ç”»é¢ï¼‰
4. bi_analysis: æ•°æ®ç»Ÿè®¡ï¼ˆé¢‘ç‡ã€è¶‹åŠ¿ï¼‰
5. report_generation: ç”ŸæˆæŠ¥å‘Š

è¯·ä¸€æ¬¡æ€§ç”Ÿæˆå®Œæ•´çš„å·¥å…·åˆ—è¡¨ï¼ŒæŒ‰æ‰§è¡Œé¡ºåºæ’åˆ—ã€‚

ä¸¥æ ¼ä»¥ JSON æ ¼å¼è¾“å‡ºï¼ˆä¸è¦åŒ…å« Markdown æ ¼å¼ï¼‰ï¼š
{
    "steps": ["tool1", "tool2", "tool3"],
    "reasoning": "ä½ çš„è§„åˆ’ç†ç”±"
}

è§„åˆ™ï¼š
- å¿…é¡»å…ˆæ‰§è¡Œ video_search
- å¦‚æœéœ€è¦ç»Ÿè®¡æˆ–æŠ¥å‘Šï¼Œåº”è¯¥åœ¨åˆ†æä¹‹å
- è®¡åˆ’è¦å®Œæ•´ï¼Œæ¶µç›–ç”¨æˆ·è¯·æ±‚çš„æ‰€æœ‰éœ€æ±‚
"""
    
    response = llm.invoke([
        ("system", system_prompt),
        ("human", input_text)
    ])
    
    content = response.content.strip()
    # å»é™¤å¯èƒ½çš„ markdown æ ‡è®°
    if content.startswith("```json"):
        content = content[7:]
    if content.startswith("```"):
        content = content[3:]
    if content.endswith("```"):
        content = content[:-3]
    
    try:
        plan_dict = json.loads(content.strip())
        plan = Plan(**plan_dict)
    except Exception as e:
        print(f"âŒ JSON è§£æå¤±è´¥: {e}")
        plan = Plan(steps=["video_search"], reasoning="è§£æå¤±è´¥ï¼Œä½¿ç”¨é»˜è®¤è®¡åˆ’")
    
    print(f"ğŸ“‹ è®¡åˆ’: {plan.steps}")
    print(f"ğŸ’¡ ç†ç”±: {plan.reasoning}")
    
    return {"plan": plan.steps}

def executor_node(state: AgentState):
    """
    æ‰§è¡ŒèŠ‚ç‚¹ï¼šæ‰¹é‡æ‰§è¡Œè®¡åˆ’åˆ—è¡¨ä¸­çš„æ‰€æœ‰å·¥å…·
    å…³é”®ï¼šå¾ªç¯æ‰§è¡Œï¼Œä¸é‡æ–°è§„åˆ’
    """
    plan = state["plan"]
    
    if not plan:
        return {}
    
    print(f"\nâš™ï¸ [Executor] å¼€å§‹æ‰§è¡Œ {len(plan)} ä¸ªæ­¥éª¤")
    
    # æ‰¹é‡æ‰§è¡Œæ‰€æœ‰æ­¥éª¤
    execution_results = []
    
    # ç®€å•çš„ä¸Šä¸‹æ–‡ä¼ é€’
    video_id = "VID_UNKNOWN"
    last_result = ""
    
    for i, tool_name in enumerate(plan, 1):
        print(f"\n[{i}/{len(plan)}] æ‰§è¡Œ: {tool_name}")
        
        result = "Error: Tool not found"
        
        # æ‰§è¡Œå·¥å…·ï¼ˆå¸¦ç®€å•çš„å‚æ•°æ¨æ–­ï¼‰
        if tool_name == "video_search":
            result = TOOL_MAP[tool_name](state["input"])
            # æå– video_id
            import re
            match = re.search(r"(VID_\w+)", result)
            if match:
                video_id = match.group(1)
        
        elif tool_name == "cv_analysis":
            event = "intrusion" if "å…¥ä¾µ" in state["input"] else "general"
            result = TOOL_MAP[tool_name](video_id, event)
        
        elif tool_name == "llm_analysis":
            result = TOOL_MAP[tool_name](video_id)
        
        elif tool_name == "bi_analysis":
            result = TOOL_MAP[tool_name](last_result)
        
        elif tool_name == "report_generation":
            context = str(execution_results)
            result = TOOL_MAP[tool_name](context)
        
        last_result = result
        step_record = f"Tool: {tool_name}, Result: {result}"
        execution_results.append(step_record)
    
    print(f"\nâœ… [Executor] æ‰€æœ‰æ­¥éª¤æ‰§è¡Œå®Œæˆ")
    
    return {
        "plan": [],  # æ¸…ç©ºè®¡åˆ’ï¼ˆè¡¨ç¤ºå·²å®Œæˆï¼‰
        "past_steps": execution_results,
        "final_response": execution_results[-1] if execution_results else "No results"
    }

# ==========================================
# 4. æ„å»ºå›¾
# ==========================================

def create_plan_execute_graph():
    workflow = StateGraph(AgentState)
    
    workflow.add_node("planner", planner_node)
    workflow.add_node("executor", executor_node)
    
    # å…³é”®ï¼šçº¿æ€§æµç¨‹ï¼Œä¸å›å¤´
    workflow.set_entry_point("planner")
    workflow.add_edge("planner", "executor")
    workflow.add_edge("executor", END)  # â† æ‰§è¡Œå®Œç›´æ¥ç»“æŸï¼Œä¸é‡æ–°è§„åˆ’
    
    checkpointer = MemorySaver()
    return workflow.compile(checkpointer=checkpointer)

# ==========================================
# 5. è¿è¡Œ
# ==========================================

def run_demo(query: str, thread_id: str = "default"):
    print(f"\n{'='*70}")
    print(f"ğŸ—£ï¸  ç”¨æˆ·æŒ‡ä»¤: {query}")
    print(f"ğŸ†” Thread ID: {thread_id}")
    print(f"{'='*70}")
    
    app = create_plan_execute_graph()
    config = {"configurable": {"thread_id": thread_id}}
    
    result = app.invoke({
        "input": query,
        "plan": [],
        "past_steps": [],
        "final_response": ""
    }, config=config)
    
    print(f"\n{'='*70}")
    print("âœ… æµç¨‹ç»“æŸ")
    print(f"ğŸ“Š æ‰§è¡Œäº† {len(result.get('past_steps', []))} ä¸ªæ­¥éª¤")
    print(f"{'='*70}\n")
    
    return result

if __name__ == "__main__":
    # åœºæ™¯ 1ï¼šå®Œæ•´æµç¨‹
    run_demo(
        "å¸®æˆ‘æ‰¾ä¸‹é¾™å±±è·¯çš„è§†é¢‘ï¼Œæ£€æµ‹æœ‰æ²¡æœ‰äººå‘˜å…¥ä¾µã€‚å¦‚æœæœ‰çš„è¯ï¼Œç”Ÿæˆä¸€ä»½æŠ¥å‘Šå¹¶ç»Ÿè®¡é¢‘ç‡ã€‚",
        thread_id="task_001"
    )
    
    # åœºæ™¯ 2ï¼šç®€å•ä»»åŠ¡
    run_demo(
        "å¸®æˆ‘æ‰¾ä¸‹äººæ°‘è·¯çš„è§†é¢‘ï¼Œåšä¸ªå†…å®¹æ€»ç»“",
        thread_id="task_002"
    )
