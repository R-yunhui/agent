"""
LangGraph åŸºç¡€ç¤ºä¾‹5ï¼šå¾ªçŽ¯å’Œè¿­ä»£
æ¼”ç¤ºå¦‚ä½•åœ¨å›¾ä¸­ä½¿ç”¨å¾ªçŽ¯è¿›è¡Œè¿­ä»£ä¼˜åŒ–
"""
import os
from typing import TypedDict, Literal
from dotenv import load_dotenv
from langgraph.graph import StateGraph, END
from langchain_openai import ChatOpenAI
from langchain_core.messages import HumanMessage, SystemMessage

# åŠ è½½çŽ¯å¢ƒå˜é‡
load_dotenv()


# 1. å®šä¹‰çŠ¶æ€
class IterativeState(TypedDict):
    """è¿­ä»£ä¼˜åŒ–çŠ¶æ€"""
    original_text: str  # åŽŸå§‹æ–‡æœ¬
    current_text: str  # å½“å‰æ–‡æœ¬
    iteration: int  # å½“å‰è¿­ä»£æ¬¡æ•°
    max_iterations: int  # æœ€å¤§è¿­ä»£æ¬¡æ•°
    quality_score: float  # è´¨é‡è¯„åˆ† (0-10)
    improvements: list  # æ”¹è¿›åŽ†å²


# 2. åˆ›å»ºLLM
llm = ChatOpenAI(
    model="gpt-3.5-turbo",
    temperature=0.7,
    api_key=os.getenv("OPENAI_API_KEY")
)


# 3. å®šä¹‰èŠ‚ç‚¹å‡½æ•°
def improve_text(state: IterativeState) -> IterativeState:
    """æ”¹è¿›æ–‡æœ¬èŠ‚ç‚¹"""
    print(f"\nðŸ”„ è¿­ä»£ {state['iteration']}/{state['max_iterations']}")
    
    messages = [
        SystemMessage(content="""ä½ æ˜¯ä¸€ä¸ªæ–‡æœ¬ä¼˜åŒ–ä¸“å®¶ã€‚è¯·æ”¹è¿›ç»™å®šçš„æ–‡æœ¬ï¼Œä½¿å…¶æ›´åŠ æ¸…æ™°ã€ä¸“ä¸šå’Œæ˜“è¯»ã€‚
åªè¿”å›žæ”¹è¿›åŽçš„æ–‡æœ¬ï¼Œä¸è¦æ·»åŠ é¢å¤–è¯´æ˜Žã€‚"""),
        HumanMessage(content=f"è¯·ä¼˜åŒ–ä»¥ä¸‹æ–‡æœ¬ï¼š\n\n{state['current_text']}")
    ]
    
    response = llm.invoke(messages)
    improved_text = response.content.strip()
    
    # è®°å½•æ”¹è¿›
    state['improvements'].append({
        'iteration': state['iteration'],
        'text': improved_text
    })
    
    state['current_text'] = improved_text
    print(f"âœ“ æ–‡æœ¬å·²ä¼˜åŒ–")
    
    return state


def evaluate_quality(state: IterativeState) -> IterativeState:
    """è¯„ä¼°æ–‡æœ¬è´¨é‡"""
    print("ðŸ“Š è¯„ä¼°è´¨é‡...")
    
    messages = [
        SystemMessage(content="""ä½ æ˜¯ä¸€ä¸ªæ–‡æœ¬è´¨é‡è¯„ä¼°ä¸“å®¶ã€‚
è¯·å¯¹æ–‡æœ¬çš„æ¸…æ™°åº¦ã€ä¸“ä¸šæ€§å’Œå¯è¯»æ€§è¿›è¡Œè¯„åˆ†ï¼ˆ0-10åˆ†ï¼‰ã€‚
åªè¿”å›žä¸€ä¸ªæ•°å­—åˆ†æ•°ï¼Œä¸è¦æœ‰å…¶ä»–å†…å®¹ã€‚"""),
        HumanMessage(content=f"è¯·è¯„åˆ†ï¼š\n\n{state['current_text']}")
    ]
    
    response = llm.invoke(messages)
    
    # å°è¯•æå–åˆ†æ•°
    try:
        score = float(response.content.strip().split()[0])
        score = max(0, min(10, score))  # ç¡®ä¿åœ¨0-10èŒƒå›´å†…
    except:
        score = 7.0  # é»˜è®¤åˆ†æ•°
    
    state['quality_score'] = score
    state['iteration'] += 1
    
    print(f"âœ“ è´¨é‡è¯„åˆ†: {score}/10")
    
    return state


def should_continue(state: IterativeState) -> Literal["continue", "end"]:
    """å†³å®šæ˜¯å¦ç»§ç»­è¿­ä»£"""
    # å¦‚æžœè¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œæˆ–è´¨é‡è¶³å¤Ÿé«˜ï¼Œåˆ™åœæ­¢
    if state['iteration'] > state['max_iterations']:
        print("â†’ è¾¾åˆ°æœ€å¤§è¿­ä»£æ¬¡æ•°ï¼Œåœæ­¢ä¼˜åŒ–")
        return "end"
    
    if state['quality_score'] >= 9.0:
        print("â†’ è´¨é‡å·²è¾¾æ ‡ï¼Œåœæ­¢ä¼˜åŒ–")
        return "end"
    
    print("â†’ ç»§ç»­ä¼˜åŒ–")
    return "continue"


# 4. åˆ›å»ºå¾ªçŽ¯å›¾
def create_iterative_graph():
    """åˆ›å»ºå¸¦å¾ªçŽ¯çš„è¿­ä»£ä¼˜åŒ–å›¾"""
    workflow = StateGraph(IterativeState)
    
    # æ·»åŠ èŠ‚ç‚¹
    workflow.add_node("improve", improve_text)
    workflow.add_node("evaluate", evaluate_quality)
    
    # è®¾ç½®å…¥å£
    workflow.set_entry_point("improve")
    
    # æ”¹è¿›åŽè¯„ä¼°
    workflow.add_edge("improve", "evaluate")
    
    # æ ¹æ®è¯„ä¼°ç»“æžœå†³å®šæ˜¯å¦ç»§ç»­
    workflow.add_conditional_edges(
        "evaluate",
        should_continue,
        {
            "continue": "improve",  # ç»§ç»­å¾ªçŽ¯
            "end": END  # ç»“æŸ
        }
    )
    
    return workflow.compile()


# 5. è¿è¡Œç¤ºä¾‹
if __name__ == "__main__":
    app = create_iterative_graph()
    
    print("=" * 70)
    print("LangGraph å¾ªçŽ¯è¿­ä»£ç¤ºä¾‹ - æ–‡æœ¬ä¼˜åŒ–å™¨")
    print("=" * 70)
    
    # åŽŸå§‹æ–‡æœ¬ï¼ˆæ•…æ„å†™å¾—ä¸å¤ªå¥½ï¼‰
    original_text = """
    è¿™ä¸ªäº§å“å¾ˆå¥½ç”¨ï¼Œæˆ‘ç”¨äº†ä¹‹åŽæ„Ÿè§‰è¿˜ä¸é”™ï¼ŒæŒºæ–¹ä¾¿çš„ã€‚
    å°±æ˜¯æœ‰æ—¶å€™ä¼šæœ‰ç‚¹å¡ï¼Œä¸è¿‡æ€»çš„æ¥è¯´è¿˜å¯ä»¥å§ã€‚
    ä»·æ ¼ä¹Ÿä¸è´µï¼Œæ€§ä»·æ¯”æŒºé«˜çš„ã€‚
    """
    
    print(f"\nðŸ“ åŽŸå§‹æ–‡æœ¬:")
    print("-" * 70)
    print(original_text.strip())
    print("-" * 70)
    
    # è¿è¡Œè¿­ä»£ä¼˜åŒ–
    result = app.invoke({
        "original_text": original_text,
        "current_text": original_text,
        "iteration": 1,
        "max_iterations": 3,
        "quality_score": 0.0,
        "improvements": []
    })
    
    # æ˜¾ç¤ºç»“æžœ
    print("\n" + "=" * 70)
    print("ä¼˜åŒ–å®Œæˆï¼")
    print("=" * 70)
    
    print(f"\nðŸ“ˆ ä¼˜åŒ–è¿‡ç¨‹:")
    for imp in result['improvements']:
        print(f"\n--- è¿­ä»£ {imp['iteration']} ---")
        print(imp['text'][:150] + "..." if len(imp['text']) > 150 else imp['text'])
    
    print(f"\nâœ¨ æœ€ç»ˆæ–‡æœ¬:")
    print("=" * 70)
    print(result['current_text'])
    print("=" * 70)
    print(f"\næœ€ç»ˆè¯„åˆ†: {result['quality_score']}/10")
    print(f"æ€»è¿­ä»£æ¬¡æ•°: {len(result['improvements'])}")
