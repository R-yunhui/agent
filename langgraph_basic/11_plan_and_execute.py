# LangGraph åŠ¨æ€è§„åˆ’ä¸æ‰§è¡Œ (Plan-and-Execute) æ¨¡å¼
# åœºæ™¯ï¼šå®Œå…¨åŠ¨æ€çš„æµç¨‹ï¼Œç”± Agent æ ¹æ®æ¯ä¸€æ­¥çš„ç»“æœå®æ—¶å†³å®šä¸‹ä¸€æ­¥åšä»€ä¹ˆ

import os
import time
import json
from typing import TypedDict, List, Annotated, Union
import operator
from dotenv import load_dotenv
from langchain_openai import ChatOpenAI
from pydantic import BaseModel, Field
from langchain_core.messages import SystemMessage, HumanMessage
from langgraph.graph import StateGraph, END
from langgraph.checkpoint.memory import MemorySaver

load_dotenv()

# ==========================================
# 1. å®šä¹‰å·¥å…· (Mock)
# ==========================================

def video_search_tool(query: str):
    """æ£€ç´¢è§†é¢‘"""
    print(f"   ğŸ› ï¸ [æ‰§è¡Œå·¥å…·] è§†é¢‘æ£€ç´¢: {query}")
    time.sleep(0.5)
    return "Found video: VID_20240520_001 (Title: City Traffic)"

def video_cv_analysis_tool(video_id: str, event_type: str = "general"):
    """CVåˆ†æ"""
    print(f"   ğŸ› ï¸ [æ‰§è¡Œå·¥å…·] CVåˆ†æ: {video_id}, äº‹ä»¶: {event_type}")
    time.sleep(1)
    # æ¨¡æ‹Ÿï¼šå¦‚æœæ˜¯æ£€æµ‹å…¥ä¾µï¼Œè¿”å›æœ‰å…¥ä¾µ
    if "å…¥ä¾µ" in event_type or "intrusion" in event_type:
        return "Detected: 2 Person Intrusion Events at 10:05 and 10:15"
    return "Detected: 5 Cars, 2 Buses, 10 Pedestrians"

def video_llm_analysis_tool(video_id: str):
    """å¤§æ¨¡å‹åˆ†æ"""
    print(f"   ğŸ› ï¸ [æ‰§è¡Œå·¥å…·] LLMåˆ†æ: {video_id}")
    time.sleep(1)
    return "Summary: The video shows a busy street. Traffic is flowing smoothly."

def bi_analysis_tool(data: str):
    """BIåˆ†æ"""
    print(f"   ğŸ› ï¸ [æ‰§è¡Œå·¥å…·] BIç»Ÿè®¡: åŸºäº {data[:20]}...")
    time.sleep(0.5)
    return "Stats: Intrusion Frequency = 2/day (High Risk)"

def report_generation_tool(context: str):
    """æŠ¥å‘Šç”Ÿæˆ"""
    print(f"   ğŸ› ï¸ [æ‰§è¡Œå·¥å…·] ç”ŸæˆæŠ¥å‘Š...")
    return f"Report Generated based on: {context[:30]}..."

# å·¥å…·æ˜ å°„è¡¨
TOOL_MAP = {
    "video_search": video_search_tool,
    "cv_analysis": video_cv_analysis_tool,
    "llm_analysis": video_llm_analysis_tool,
    "bi_analysis": bi_analysis_tool,
    "report_generation": report_generation_tool
}

# ==========================================
# 2. å®šä¹‰çŠ¶æ€ (State)
# ==========================================

class Plan(BaseModel):
    """è®¡åˆ’æ¨¡å‹ï¼šåŒ…å«æ¥ä¸‹æ¥è¦æ‰§è¡Œçš„å·¥å…·åˆ—è¡¨"""
    steps: List[str] = Field(description="List of tool names to execute next. Available tools: video_search, cv_analysis, llm_analysis, bi_analysis, report_generation")
    reasoning: str = Field(description="Reasoning for the current plan")

class AgentState(TypedDict):
    input: str
    plan: List[str]              # å½“å‰å¾…æ‰§è¡Œçš„è®¡åˆ’é˜Ÿåˆ—
    # å…³é”®ä¿®å¤ï¼šä½¿ç”¨ operator.add ç¡®ä¿æ˜¯â€œè¿½åŠ â€è€Œä¸æ˜¯â€œè¦†ç›–â€
    # å¦‚æœä¸åŠ è¿™ä¸ªï¼Œæ¯æ¬¡ executor è¿”å›æ—¶ï¼Œæ—§çš„å†å²è®°å½•ä¼šè¢«æ¸…ç©ºï¼Œå¯¼è‡´æ¨¡å‹â€œå¤±å¿†â€ä»è€Œå¾ªç¯è°ƒç”¨
    past_steps: Annotated[List[str], operator.add]
    completed_tools: Annotated[List[str], operator.add]
    final_response: str          # æœ€ç»ˆç»“æœ

# ==========================================
# 3. èŠ‚ç‚¹å®šä¹‰
# ==========================================

def planner_node(state: AgentState):
    """
    è§„åˆ’èŠ‚ç‚¹ (Re-Planner)
    æ ¹æ®ç”¨æˆ·ç›®æ ‡ + å·²æœ‰çš„æ‰§è¡Œç»“æœï¼Œå†³å®šæ¥ä¸‹æ¥è¿˜è¦åšä»€ä¹ˆã€‚
    """
    print("\nğŸ§  [Planner] æ­£åœ¨æ€è€ƒä¸‹ä¸€æ­¥è®¡åˆ’...")
    
    input_text = state["input"]
    past_steps = state.get("past_steps", [])
    completed_tools = state.get("completed_tools", [])
    
    llm = ChatOpenAI(
        model=os.getenv("OPENAI_CHAT_MODEL"),
        base_url=os.getenv("OPENAI_API_BASE_URL"),
        api_key=os.getenv("OPENAI_API_KEY"),
        temperature=0
    )
    
    # ---------------------------------------------------------
    # ä¿®å¤ï¼šä¸ä½¿ç”¨ with_structured_outputï¼Œæ”¹ç”¨çº¯ Prompt + JSON è§£æ
    # ä»¥å…¼å®¹ä¸æ”¯æŒ response_format çš„æ¨¡å‹æ¥å£
    # ---------------------------------------------------------
    
    system_prompt = f"""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½ä»»åŠ¡è°ƒåº¦å‘˜ã€‚ä½ çš„ç›®æ ‡æ˜¯å®Œæˆç”¨æˆ·çš„è¯·æ±‚ã€‚
    
    å¯ç”¨å·¥å…·ï¼š
    1. video_search: æŸ¥æ‰¾è§†é¢‘ (å¿…é¡»å…ˆæ‰§è¡Œ)
    2. cv_analysis: è§†è§‰åˆ†æ (æ£€æµ‹ç‰©ä½“ã€å…¥ä¾µäº‹ä»¶ç­‰)
    3. llm_analysis: å†…å®¹ç†è§£ (æ€»ç»“ã€æè¿°ç”»é¢)
    4. bi_analysis: æ•°æ®ç»Ÿè®¡ (é¢‘ç‡ã€è¶‹åŠ¿)
    5. report_generation: ç”ŸæˆæŠ¥å‘Š
    
    å½“å‰å·²å®Œæˆçš„æ­¥éª¤å’Œç»“æœï¼š
    {past_steps}
    
    å·²æ‰§è¡Œè¿‡çš„å·¥å…·åˆ—è¡¨ï¼ˆç»å¯¹ä¸è¦å†æ¬¡æ‰§è¡Œï¼‰ï¼š
    {completed_tools}
    
    è¯·æ ¹æ®ç”¨æˆ·è¯·æ±‚å’Œå·²å®Œæˆçš„ç»“æœï¼Œç”Ÿæˆ**æ¥ä¸‹æ¥**éœ€è¦æ‰§è¡Œçš„å·¥å…·åˆ—è¡¨ã€‚
    
    è¯·ä¸¥æ ¼ä»¥ JSON æ ¼å¼è¾“å‡ºï¼Œä¸è¦åŒ…å« Markdown æ ¼å¼ï¼ˆå¦‚ ```jsonï¼‰ï¼Œæ ¼å¼å¦‚ä¸‹ï¼š
    {{
        "steps": ["tool_name1", "tool_name2"],
        "reasoning": "ä½ çš„ç†ç”±"
    }}
    
    è§„åˆ™ï¼š
    - ä»”ç»†æ£€æŸ¥â€œå½“å‰å·²å®Œæˆçš„æ­¥éª¤â€ï¼Œå¦‚æœæŸä¸ªå·¥å…·å·²ç»æ‰§è¡ŒæˆåŠŸï¼ˆResultä¸ä¸ºç©ºï¼‰ï¼Œ**ç»å¯¹ä¸è¦**å†æ¬¡æ·»åŠ åˆ°è®¡åˆ’ä¸­ï¼
    - å¦‚æœä»»åŠ¡å·²å…¨éƒ¨å®Œæˆï¼ˆæ‰€æœ‰è¦æ±‚çš„åˆ†æéƒ½å·²åœ¨ past_steps ä¸­å‡ºç°ï¼‰ï¼Œ"steps" è¿”å›ç©ºåˆ—è¡¨ []ã€‚
    - å¦‚æœéœ€è¦æ ¹æ®ä¸Šä¸€æ­¥çš„ç»“æœå†³å®šä¸‹ä¸€æ­¥ï¼ˆä¾‹å¦‚ï¼šåªæœ‰æ£€æµ‹åˆ°å…¥ä¾µæ‰ç”ŸæˆæŠ¥å‘Šï¼‰ï¼Œè¯·åœ¨å½“å‰è®¡åˆ’ä¸­åªåŒ…å«ä¸‹ä¸€æ­¥ã€‚
    - ä¸è¦æ­»å¾ªç¯ã€‚å¦‚æœå‘ç°è‡ªå·±é‡å¤å»ºè®®åŒä¸€ä¸ªå·¥å…·ï¼Œè¯·ç«‹å³åœæ­¢ã€‚
    """
    
    response = llm.invoke([
        ("system", system_prompt),
        ("human", input_text)
    ])
    
    # ç®€å•çš„ JSON è§£æ
    content = response.content.strip()
    # å»é™¤å¯èƒ½çš„ markdown ä»£ç å—æ ‡è®°
    if content.startswith("```json"):
        content = content[7:]
    if content.startswith("```"):
        content = content[3:]
    if content.endswith("```"):
        content = content[:-3]
    
    try:
        plan_dict = json.loads(content)
        plan = Plan(**plan_dict)
    except Exception as e:
        print(f"âŒ [Planner] JSON è§£æå¤±è´¥: {e}, åŸå§‹å†…å®¹: {content}")
        # å…œåº•ç­–ç•¥ï¼šå¦‚æœè§£æå¤±è´¥ï¼Œå‡è®¾ç»“æŸ
        plan = Plan(steps=[], reasoning="è§£æå¤±è´¥ï¼Œåœæ­¢æ‰§è¡Œ")
    
    # å…³é”®ï¼šæ˜¾å¼è¿‡æ»¤æ‰å·²ç»æ‰§è¡Œè¿‡çš„å·¥å…·
    filtered_steps = [step for step in plan.steps if step not in completed_tools]
    
    if len(filtered_steps) < len(plan.steps):
        print(f"âš ï¸ [Planner] è¿‡æ»¤äº†é‡å¤çš„å·¥å…·: {set(plan.steps) - set(filtered_steps)}")
    
    print(f"ğŸ“‹ [Planner] æ›´æ–°è®¡åˆ’: {filtered_steps} (ç†ç”±: {plan.reasoning})")
    
    return {"plan": filtered_steps}

def executor_node(state: AgentState):
    """
    æ‰§è¡ŒèŠ‚ç‚¹
    ä»è®¡åˆ’é˜Ÿåˆ—ä¸­å–å‡ºç¬¬ä¸€ä¸ªå·¥å…·å¹¶æ‰§è¡Œã€‚
    """
    plan = state["plan"]
    if not plan:
        return {}
    
    # å–å‡ºç¬¬ä¸€ä¸ªä»»åŠ¡
    tool_name = plan[0]
    remaining_plan = plan[1:]
    
    print(f"ğŸ‘‰ [Executor] å‡†å¤‡æ‰§è¡Œ: {tool_name}")
    
    # --- ç®€å•çš„ä¸Šä¸‹æ–‡æå–é€»è¾‘ ---
    # å°è¯•ä»å†å²è®°å½•ä¸­æå– video_id
    import re
    video_id = "VID_UNKNOWN"
    for step in state.get("past_steps", []):
        # å‡è®¾ search ç»“æœåŒ…å« "Found video: VID_..."
        match = re.search(r"(VID_\w+)", step)
        if match:
            video_id = match.group(1)
            
    # æ‰§è¡Œé€»è¾‘
    result = "Error: Tool not found"
    
    # ç®€å•çš„å‚æ•°æ³¨å…¥é€»è¾‘
    if tool_name == "video_search":
        result = TOOL_MAP[tool_name](state["input"])
    elif tool_name == "cv_analysis":
        # ç®€å•åˆ¤æ–­å‚æ•°
        event = "intrusion" if "å…¥ä¾µ" in state["input"] else "general"
        result = TOOL_MAP[tool_name](video_id, event)
    elif tool_name == "llm_analysis":
        result = TOOL_MAP[tool_name](video_id)
    elif tool_name == "bi_analysis":
        # è·å–ä¹‹å‰çš„ CV ç»“æœä½œä¸ºè¾“å…¥
        last_result = state["past_steps"][-1] if state["past_steps"] else ""
        result = TOOL_MAP[tool_name](last_result)
    elif tool_name == "report_generation":
        # æ±‡æ€»æ‰€æœ‰å†å²ä¿¡æ¯
        context = str(state["past_steps"])
        result = TOOL_MAP[tool_name](context)
    
    # è®°å½•æ‰§è¡Œç»“æœ
    step_record = f"Tool: {tool_name}, Result: {result}"
    
    # æ›´æ–°çŠ¶æ€ï¼š
    # 1. å‡å°‘å¾…æ‰§è¡Œè®¡åˆ’
    # 2. å¢åŠ å†å²è®°å½•
    # 3. ã€å…³é”®ã€‘æŠŠå·¥å…·ååŠ å…¥ completed_tools
    return {
        "plan": remaining_plan,
        "past_steps": [step_record],
        "completed_tools": [tool_name]
    }

# ==========================================
# 4. è·¯ç”±é€»è¾‘
# ==========================================

def should_continue(state: AgentState):
    """
    å†³å®šæ˜¯ç»§ç»­æ‰§è¡Œï¼Œè¿˜æ˜¯é‡æ–°è§„åˆ’ï¼Œè¿˜æ˜¯ç»“æŸ
    è¿™é‡Œé‡‡ç”¨ï¼šæ‰§è¡Œä¸€æ­¥ -> é‡æ–°è§„åˆ’ (Re-Plan) çš„æ¨¡å¼ï¼Œä»¥å®ç°æœ€å¤§çµæ´»æ€§ã€‚
    """
    plan = state["plan"]
    
    # å¦‚æœè®¡åˆ’ä¸ºç©ºï¼Œè¯´æ˜ Planner è®¤ä¸ºæ²¡æ´»å¹²äº†ï¼Œç»“æŸ
    if not plan:
        return END
    
    # å¦åˆ™ï¼Œå»æ‰§è¡Œ
    return "executor"

def after_execution(state: AgentState):
    """
    æ‰§è¡Œå®Œä¸€æ­¥åï¼Œæ€»æ˜¯å›åˆ° Planner è¿›è¡Œé‡æ–°è¯„ä¼° (Re-Plan)
    è¿™æ ·å¯ä»¥å¤„ç† "å¦‚æœ CV å‘ç°å…¥ä¾µï¼Œåˆ™æ·»åŠ  Report ä»»åŠ¡" è¿™ç§åŠ¨æ€é€»è¾‘
    """
    return "planner"

# ==========================================
# 5. æ„å»ºå›¾
# ==========================================

def create_plan_execute_graph():
    workflow = StateGraph(AgentState)
    
    workflow.add_node("planner", planner_node)
    workflow.add_node("executor", executor_node)
    
    workflow.set_entry_point("planner")
    
    workflow.add_conditional_edges(
        "planner",
        should_continue,
        {
            "executor": "executor",
            END: END
        }
    )
    
    workflow.add_edge("executor", "planner")
    
    # å…³é”®ï¼šå¯ç”¨ Checkpointerï¼ˆå†…å­˜æ£€æŸ¥ç‚¹ï¼‰
    # æ¯æ¬¡èŠ‚ç‚¹æ‰§è¡Œåï¼ŒLangGraph ä¼šè‡ªåŠ¨ä¿å­˜æ•´ä¸ª State
    checkpointer = MemorySaver()
    
    return workflow.compile(checkpointer=checkpointer)

# ==========================================
# 6. è¿è¡Œ
# ==========================================

def run_demo(query: str, thread_id: str = "default"):
    print(f"ğŸ—£ï¸ ç”¨æˆ·æŒ‡ä»¤: {query}")
    print(f"ğŸ†” Thread ID: {thread_id}")
    print("#" * 60)
    
    app = create_plan_execute_graph()
    
    # å…³é”®ï¼šä½¿ç”¨ config å‚æ•°ä¼ å…¥ thread_id
    # LangGraph ä¼šè‡ªåŠ¨åŠ è½½è¯¥ thread çš„å†å²çŠ¶æ€ï¼ˆå¦‚æœå­˜åœ¨ï¼‰
    config = {"configurable": {"thread_id": thread_id}}
    
    result = app.invoke({
        "input": query,
        "plan": [],
        "past_steps": [],
        "completed_tools": []
    }, config=config)
    
    print("\nâœ… æµç¨‹ç»“æŸ")
    print(f"ğŸ“Š æœ€ç»ˆçŠ¶æ€: å·²æ‰§è¡Œå·¥å…· = {result.get('completed_tools', [])}")
    
    return result

if __name__ == "__main__":
    # åœºæ™¯ 1ï¼šå®Œæ•´æµç¨‹ï¼ˆæ¡ä»¶æ‰§è¡Œï¼‰
    print("ğŸ¯ åœºæ™¯ 1: å®Œæ•´æµç¨‹ - æ£€æµ‹å…¥ä¾µå¹¶ç”ŸæˆæŠ¥å‘Š")
    print("=" * 70)
    
    run_demo(
        "å¸®æˆ‘æ‰¾ä¸‹é¾™å±±è·¯çš„è§†é¢‘ï¼Œæ£€æµ‹æœ‰æ²¡æœ‰äººå‘˜å…¥ä¾µã€‚å¦‚æœæœ‰çš„è¯ï¼Œç”Ÿæˆä¸€ä»½æŠ¥å‘Šå¹¶ç»Ÿè®¡é¢‘ç‡ã€‚",
        thread_id="task_001"
    )
    
    # åœºæ™¯ 2ï¼šç®€å•ä»»åŠ¡ï¼ˆæ¼”ç¤º Checkpointer çš„è®°å¿†éš”ç¦»ï¼‰
    print("ğŸ¯ åœºæ™¯ 2: ç®€å•ä»»åŠ¡ - ä»…æ£€ç´¢è§†é¢‘ï¼ˆä¸åŒ thread_idï¼‰")
    print("=" * 70)
    
    run_demo(
        "å¸®æˆ‘æ‰¾ä¸‹äººæ°‘è·¯çš„è§†é¢‘",
        thread_id="task_002"  # ä¸åŒçš„ thread_idï¼ŒçŠ¶æ€å®Œå…¨éš”ç¦»
    )
