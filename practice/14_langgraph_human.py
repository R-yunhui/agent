"""
Human In The Loop + LangGraph å®Œæ•´ç¤ºä¾‹

æœ¬ç¤ºä¾‹å±•ç¤ºäº† LangGraph ä¸­å®ç°äººæœºåä½œçš„å‡ ç§å¸¸è§æ¨¡å¼ï¼š
1. åŸºç¡€ä¸­æ–­æ¨¡å¼ - ä½¿ç”¨ interrupt æš‚åœæ‰§è¡Œç­‰å¾…äººç±»è¾“å…¥
2. å†…å®¹å®¡æ ¸æ¨¡å¼ - LLM ç”Ÿæˆå†…å®¹åéœ€è¦äººå·¥å®¡æ ¸ä¿®æ”¹
3. æ•æ„Ÿæ“ä½œç¡®è®¤æ¨¡å¼ - æ‰§è¡Œæ•æ„Ÿå·¥å…·è°ƒç”¨å‰éœ€è¦äººå·¥ç¡®è®¤
4. å¤šè½®å¯¹è¯ä¸­æ–­æ¨¡å¼ - åœ¨å¯¹è¯è¿‡ç¨‹ä¸­è¯·æ±‚äººç±»ååŠ©
"""

import os
import uuid
from typing import TypedDict, Annotated, Literal
from operator import add

from dotenv import load_dotenv
from langgraph.graph import StateGraph, START, END
from langgraph.checkpoint.memory import InMemorySaver
from langgraph.types import interrupt, Command
from langchain_community.chat_models import ChatTongyi
from langchain_core.messages import HumanMessage, AIMessage, SystemMessage, BaseMessage
from langchain_core.tools import tool

load_dotenv()

# åˆå§‹åŒ– LLM
llm = ChatTongyi(
    model=os.getenv("TONGYI_MODEL"),
    api_key=os.getenv("DASHSCOPE_KEY"),
)


# ============================================
# ç¤ºä¾‹ 1: åŸºç¡€ä¸­æ–­æ¨¡å¼ - ç®€å•çš„æ–‡æœ¬å®¡æ ¸
# ============================================
def example_1_basic_interrupt():
    """åŸºç¡€ä¸­æ–­æ¨¡å¼ï¼šäººå·¥å®¡æ ¸å¹¶ç¼–è¾‘æ–‡æœ¬"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 1: åŸºç¡€ä¸­æ–­æ¨¡å¼ - ç®€å•çš„æ–‡æœ¬å®¡æ ¸")
    print("=" * 60)

    class State(TypedDict):
        text: str
        approved: bool

    def generate_text(state: State) -> dict:
        """ç”Ÿæˆæ–‡æœ¬èŠ‚ç‚¹"""
        return {"text": "è¿™æ˜¯ä¸€æ®µè‡ªåŠ¨ç”Ÿæˆçš„æ–‡æœ¬ï¼Œå¯èƒ½éœ€è¦äººå·¥å®¡æ ¸å’Œä¿®æ”¹ã€‚"}

    def human_review(state: State) -> dict:
        """äººå·¥å®¡æ ¸èŠ‚ç‚¹ - ä½¿ç”¨ interrupt æš‚åœç­‰å¾…äººç±»è¾“å…¥"""
        result = interrupt({
            "task": "è¯·å®¡æ ¸ä»¥ä¸‹æ–‡æœ¬ï¼Œå¯ä»¥é€‰æ‹©æ‰¹å‡†æˆ–ä¿®æ”¹",
            "current_text": state["text"],
            "options": ["approve", "edit", "reject"]
        })

        if result["action"] == "approve":
            return {"approved": True}
        elif result["action"] == "edit":
            return {"text": result["edited_text"], "approved": True}
        else:
            return {"text": "æ–‡æœ¬è¢«æ‹’ç»", "approved": False}

    def process_result(state: State) -> dict:
        """å¤„ç†å®¡æ ¸ç»“æœ"""
        if state["approved"]:
            print(f"âœ… æ–‡æœ¬å·²é€šè¿‡å®¡æ ¸: {state['text']}")
        else:
            print(f"âŒ æ–‡æœ¬è¢«æ‹’ç»")
        return state

    # æ„å»ºå›¾
    builder = StateGraph(State)
    builder.add_node("generate_text", generate_text)
    builder.add_node("human_review", human_review)
    builder.add_node("process_result", process_result)

    builder.add_edge(START, "generate_text")
    builder.add_edge("generate_text", "human_review")
    builder.add_edge("human_review", "process_result")
    builder.add_edge("process_result", END)

    # ç¼–è¯‘å›¾ï¼ˆéœ€è¦ checkpointer æ¥æ”¯æŒä¸­æ–­ï¼‰
    checkpointer = InMemorySaver()
    graph = builder.compile(checkpointer=checkpointer)

    # æ‰§è¡Œå›¾ç›´åˆ°ä¸­æ–­ç‚¹
    config = {"configurable": {"thread_id": str(uuid.uuid4())}}
    result = graph.invoke({"text": "", "approved": False}, config=config)

    # æ‰“å°ä¸­æ–­ä¿¡æ¯
    print("\nğŸ“‹ æ”¶åˆ°ä¸­æ–­è¯·æ±‚:")
    interrupt_info = result["__interrupt__"][0]
    print(f"  ä»»åŠ¡: {interrupt_info.value['task']}")
    print(f"  å½“å‰æ–‡æœ¬: {interrupt_info.value['current_text']}")
    print(f"  å¯é€‰æ“ä½œ: {interrupt_info.value['options']}")

    # æ¨¡æ‹Ÿäººç±»è¾“å…¥ï¼ˆç¼–è¾‘æ–‡æœ¬ï¼‰
    print("\nğŸ‘¤ äººç±»æ“ä½œ: é€‰æ‹©ç¼–è¾‘æ–‡æœ¬")
    human_response = {
        "action": "edit",
        "edited_text": "è¿™æ˜¯ç»è¿‡äººå·¥å®¡æ ¸å’Œä¿®æ”¹åçš„ä¼˜è´¨æ–‡æœ¬å†…å®¹ã€‚"
    }

    # æ¢å¤æ‰§è¡Œ
    final_result = graph.invoke(Command(resume=human_response), config=config)
    print(f"\nğŸ“„ æœ€ç»ˆæ–‡æœ¬: {final_result['text']}")


# ============================================
# ç¤ºä¾‹ 2: å†…å®¹ç”Ÿæˆ + äººå·¥å®¡æ ¸æ¨¡å¼
# ============================================
def example_2_content_review():
    """LLM ç”Ÿæˆå†…å®¹åè¿›è¡Œäººå·¥å®¡æ ¸"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 2: LLM å†…å®¹ç”Ÿæˆ + äººå·¥å®¡æ ¸æ¨¡å¼")
    print("=" * 60)

    class State(TypedDict):
        topic: str
        draft: str
        final_content: str
        revision_count: int

    def generate_draft(state: State) -> dict:
        """ä½¿ç”¨ LLM ç”Ÿæˆåˆç¨¿"""
        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹åˆ›ä½œè€…ï¼Œè¯·æ ¹æ®ä¸»é¢˜ç”Ÿæˆä¸€æ®µç®€çŸ­çš„å†…å®¹ã€‚"),
            HumanMessage(content=f"è¯·ä¸ºä»¥ä¸‹ä¸»é¢˜ç”Ÿæˆä¸€æ®µ 50 å­—å·¦å³çš„å†…å®¹ï¼š{state['topic']}")
        ]
        response = llm.invoke(messages)
        return {"draft": response.content, "revision_count": 0}

    def human_review_edit(state: State) -> dict:
        """äººå·¥å®¡æ ¸å’Œç¼–è¾‘èŠ‚ç‚¹"""
        result = interrupt({
            "task": "è¯·å®¡æ ¸ AI ç”Ÿæˆçš„å†…å®¹è‰ç¨¿",
            "topic": state["topic"],
            "draft": state["draft"],
            "revision_count": state["revision_count"],
            "instructions": "è¯·é€‰æ‹©: approve(æ‰¹å‡†), edit(ç¼–è¾‘), regenerate(é‡æ–°ç”Ÿæˆ)"
        })

        if result["action"] == "approve":
            return {"final_content": state["draft"]}
        elif result["action"] == "edit":
            return {"final_content": result["edited_content"]}
        elif result["action"] == "regenerate":
            return {"revision_count": state["revision_count"] + 1}
        return {}

    def should_regenerate(state: State) -> Literal["regenerate", "finalize"]:
        """å†³å®šæ˜¯å¦éœ€è¦é‡æ–°ç”Ÿæˆ"""
        if state.get("final_content"):
            return "finalize"
        return "regenerate"

    def regenerate_draft(state: State) -> dict:
        """é‡æ–°ç”Ÿæˆè‰ç¨¿"""
        messages = [
            SystemMessage(content="ä½ æ˜¯ä¸€ä¸ªä¸“ä¸šçš„å†…å®¹åˆ›ä½œè€…ï¼Œè¯·æ ¹æ®ä¸»é¢˜é‡æ–°ç”Ÿæˆå†…å®¹ï¼Œå°è¯•ä¸åŒçš„è§’åº¦ã€‚"),
            HumanMessage(content=f"è¯·ä¸ºä¸»é¢˜ '{state['topic']}' é‡æ–°ç”Ÿæˆå†…å®¹ï¼ˆç¬¬ {state['revision_count'] + 1} æ¬¡å°è¯•ï¼‰")
        ]
        response = llm.invoke(messages)
        return {"draft": response.content}

    def finalize_content(state: State) -> dict:
        """æœ€ç»ˆç¡®è®¤å†…å®¹"""
        print(f"\nâœ… å†…å®¹å·²æœ€ç»ˆç¡®è®¤!")
        print(f"ğŸ“ æœ€ç»ˆå†…å®¹: {state['final_content']}")
        return state

    # æ„å»ºå›¾
    builder = StateGraph(State)
    builder.add_node("generate_draft", generate_draft)
    builder.add_node("human_review_edit", human_review_edit)
    builder.add_node("regenerate_draft", regenerate_draft)
    builder.add_node("finalize_content", finalize_content)

    builder.add_edge(START, "generate_draft")
    builder.add_edge("generate_draft", "human_review_edit")
    builder.add_conditional_edges(
        "human_review_edit",
        should_regenerate,
        {"regenerate": "regenerate_draft", "finalize": "finalize_content"}
    )
    builder.add_edge("regenerate_draft", "human_review_edit")
    builder.add_edge("finalize_content", END)

    checkpointer = InMemorySaver()
    graph = builder.compile(checkpointer=checkpointer)

    # æ‰§è¡Œ
    config = {"configurable": {"thread_id": str(uuid.uuid4())}}
    result = graph.invoke(
        {"topic": "äººå·¥æ™ºèƒ½çš„æœªæ¥å‘å±•", "draft": "", "final_content": "", "revision_count": 0},
        config=config
    )

    # æ‰“å°ä¸­æ–­ä¿¡æ¯
    print("\nğŸ“‹ æ”¶åˆ°å®¡æ ¸è¯·æ±‚:")
    interrupt_info = result["__interrupt__"][0]
    print(f"  ä¸»é¢˜: {interrupt_info.value['topic']}")
    print(f"  AI è‰ç¨¿: {interrupt_info.value['draft']}")

    # æ¨¡æ‹Ÿäººç±»æ‰¹å‡†
    print("\nğŸ‘¤ äººç±»æ“ä½œ: æ‰¹å‡†å†…å®¹")
    human_response = {"action": "approve"}

    # æ¢å¤æ‰§è¡Œ
    final_result = graph.invoke(Command(resume=human_response), config=config)


# ============================================
# ç¤ºä¾‹ 3: æ•æ„Ÿå·¥å…·è°ƒç”¨ç¡®è®¤æ¨¡å¼
# ============================================
def example_3_tool_approval():
    """æ•æ„Ÿæ“ä½œéœ€è¦äººå·¥ç¡®è®¤"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 3: æ•æ„Ÿå·¥å…·è°ƒç”¨ç¡®è®¤æ¨¡å¼")
    print("=" * 60)

    class State(TypedDict):
        user_request: str
        action_type: str
        action_params: dict
        action_approved: bool
        result: str

    def analyze_request(state: State) -> dict:
        """åˆ†æç”¨æˆ·è¯·æ±‚ï¼Œç¡®å®šéœ€è¦æ‰§è¡Œçš„æ“ä½œ"""
        messages = [
            SystemMessage(content="""ä½ æ˜¯ä¸€ä¸ªæ™ºèƒ½åŠ©æ‰‹ã€‚åˆ†æç”¨æˆ·è¯·æ±‚å¹¶ç¡®å®šæ“ä½œç±»å‹ã€‚
å¯é€‰æ“ä½œç±»å‹: delete_file(åˆ é™¤æ–‡ä»¶), send_email(å‘é€é‚®ä»¶), make_payment(æ”¯ä»˜), other(å…¶ä»–)
è¯·ä»¥ JSON æ ¼å¼è¿”å›: {"action_type": "xxx", "params": {...}}"""),
            HumanMessage(content=state["user_request"])
        ]
        response = llm.invoke(messages)

        # ç®€åŒ–å¤„ç†ï¼šæ¨¡æ‹Ÿè§£æç»“æœ
        return {
            "action_type": "delete_file",
            "action_params": {"file_path": "/important/data.txt"}
        }

    def request_approval(state: State) -> dict:
        """å¯¹æ•æ„Ÿæ“ä½œè¯·æ±‚äººå·¥ç¡®è®¤"""
        # å®šä¹‰æ•æ„Ÿæ“ä½œåˆ—è¡¨
        sensitive_actions = ["delete_file", "send_email", "make_payment"]

        if state["action_type"] in sensitive_actions:
            result = interrupt({
                "warning": "âš ï¸ æ£€æµ‹åˆ°æ•æ„Ÿæ“ä½œï¼Œéœ€è¦äººå·¥ç¡®è®¤!",
                "action_type": state["action_type"],
                "action_params": state["action_params"],
                "question": "æ˜¯å¦æ‰¹å‡†æ‰§è¡Œæ­¤æ“ä½œï¼Ÿ(approve/reject)"
            })
            return {"action_approved": result["approved"]}
        else:
            return {"action_approved": True}

    def execute_action(state: State) -> dict:
        """æ‰§è¡Œæ“ä½œ"""
        if state["action_approved"]:
            # æ¨¡æ‹Ÿæ‰§è¡Œæ“ä½œ
            print(f"\nğŸ”§ æ‰§è¡Œæ“ä½œ: {state['action_type']}")
            print(f"   å‚æ•°: {state['action_params']}")
            return {"result": f"æ“ä½œ {state['action_type']} å·²æˆåŠŸæ‰§è¡Œ"}
        else:
            return {"result": "æ“ä½œå·²è¢«ç”¨æˆ·æ‹’ç»"}

    def report_result(state: State) -> dict:
        """æŠ¥å‘Šæ‰§è¡Œç»“æœ"""
        print(f"\nğŸ“Š æ‰§è¡Œç»“æœ: {state['result']}")
        return state

    # æ„å»ºå›¾
    builder = StateGraph(State)
    builder.add_node("analyze_request", analyze_request)
    builder.add_node("request_approval", request_approval)
    builder.add_node("execute_action", execute_action)
    builder.add_node("report_result", report_result)

    builder.add_edge(START, "analyze_request")
    builder.add_edge("analyze_request", "request_approval")
    builder.add_edge("request_approval", "execute_action")
    builder.add_edge("execute_action", "report_result")
    builder.add_edge("report_result", END)

    checkpointer = InMemorySaver()
    graph = builder.compile(checkpointer=checkpointer)

    # æ‰§è¡Œ
    config = {"configurable": {"thread_id": str(uuid.uuid4())}}
    result = graph.invoke(
        {
            "user_request": "è¯·å¸®æˆ‘åˆ é™¤ /important/data.txt è¿™ä¸ªæ–‡ä»¶",
            "action_type": "",
            "action_params": {},
            "action_approved": False,
            "result": ""
        },
        config=config
    )

    # æ‰“å°ä¸­æ–­ä¿¡æ¯
    print("\nğŸš¨ æ”¶åˆ°ç¡®è®¤è¯·æ±‚:")
    interrupt_info = result["__interrupt__"][0]
    print(f"  è­¦å‘Š: {interrupt_info.value['warning']}")
    print(f"  æ“ä½œç±»å‹: {interrupt_info.value['action_type']}")
    print(f"  æ“ä½œå‚æ•°: {interrupt_info.value['action_params']}")

    # æ¨¡æ‹Ÿäººç±»æ‹’ç»å±é™©æ“ä½œ
    print("\nğŸ‘¤ äººç±»æ“ä½œ: æ‹’ç»åˆ é™¤æ–‡ä»¶")
    human_response = {"approved": False}

    # æ¢å¤æ‰§è¡Œ
    final_result = graph.invoke(Command(resume=human_response), config=config)


# ============================================
# ç¤ºä¾‹ 4: å¯¹è¯ä¸­çš„äººç±»ååŠ©å·¥å…·
# ============================================
def example_4_chat_with_human_assistance():
    """åœ¨å¯¹è¯ä¸­è¯·æ±‚äººç±»ååŠ©"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 4: å¯¹è¯ä¸­çš„äººç±»ååŠ©å·¥å…·")
    print("=" * 60)

    class State(TypedDict):
        messages: Annotated[list[BaseMessage], add]
        needs_human_help: bool
        human_response: str

    @tool
    def request_human_assistance(query: str) -> str:
        """å½“ AI æ— æ³•å›ç­”é—®é¢˜æˆ–éœ€è¦äººç±»ä¸“ä¸šçŸ¥è¯†æ—¶ï¼Œè¯·æ±‚äººç±»ååŠ©ã€‚
        
        Args:
            query: éœ€è¦äººç±»ååŠ©çš„å…·ä½“é—®é¢˜
        """
        # ä½¿ç”¨ interrupt æš‚åœå¹¶ç­‰å¾…äººç±»è¾“å…¥
        result = interrupt({
            "type": "human_assistance_request",
            "query": query,
            "instructions": "AI éœ€è¦æ‚¨çš„å¸®åŠ©æ¥å›ç­”è¿™ä¸ªé—®é¢˜"
        })
        return result["answer"]

    def chatbot(state: State) -> dict:
        """èŠå¤©æœºå™¨äººèŠ‚ç‚¹"""
        # ç»‘å®šå·¥å…·åˆ° LLM
        llm_with_tools = llm.bind_tools([request_human_assistance])

        system_message = SystemMessage(content="""ä½ æ˜¯ä¸€ä¸ªæœ‰å¸®åŠ©çš„ AI åŠ©æ‰‹ã€‚
å½“é‡åˆ°ä»¥ä¸‹æƒ…å†µæ—¶ï¼Œè¯·ä½¿ç”¨ request_human_assistance å·¥å…·è¯·æ±‚äººç±»å¸®åŠ©ï¼š
1. æ¶‰åŠä¸ªäººéšç§ä¿¡æ¯
2. éœ€è¦å®æ—¶æ•°æ®ï¼ˆå¦‚å½“å‰è‚¡ä»·ï¼‰
3. éœ€è¦ä¸“ä¸šé¢†åŸŸçŸ¥è¯†
4. ä½ ä¸ç¡®å®šç­”æ¡ˆçš„æƒ…å†µ""")

        messages = [system_message] + state["messages"]
        response = llm_with_tools.invoke(messages)

        return {"messages": [response]}

    def should_use_tool(state: State) -> Literal["tool", "end"]:
        """åˆ¤æ–­æ˜¯å¦éœ€è¦è°ƒç”¨å·¥å…·"""
        last_message = state["messages"][-1]
        if hasattr(last_message, "tool_calls") and last_message.tool_calls:
            return "tool"
        return "end"

    def tool_node(state: State) -> dict:
        """å¤„ç†å·¥å…·è°ƒç”¨"""
        last_message = state["messages"][-1]
        tool_call = last_message.tool_calls[0]

        if tool_call["name"] == "request_human_assistance":
            query = tool_call["args"]["query"]
            result = interrupt({
                "type": "human_assistance_request",
                "query": query,
                "instructions": "AI éœ€è¦æ‚¨çš„å¸®åŠ©æ¥å›ç­”è¿™ä¸ªé—®é¢˜"
            })

            from langchain_core.messages import ToolMessage
            tool_response = ToolMessage(
                content=result["answer"],
                tool_call_id=tool_call["id"]
            )
            return {"messages": [tool_response]}

        return {}

    # æ„å»ºå›¾
    builder = StateGraph(State)
    builder.add_node("chatbot", chatbot)
    builder.add_node("tool", tool_node)

    builder.add_edge(START, "chatbot")
    builder.add_conditional_edges("chatbot", should_use_tool, {"tool": "tool", "end": END})
    builder.add_edge("tool", "chatbot")

    checkpointer = InMemorySaver()
    graph = builder.compile(checkpointer=checkpointer)

    # æ‰§è¡Œ - é—®ä¸€ä¸ªéœ€è¦äººç±»ååŠ©çš„é—®é¢˜
    config = {"configurable": {"thread_id": str(uuid.uuid4())}}

    print("\nğŸ’¬ ç”¨æˆ·é—®é¢˜: æˆ‘ä»¬å…¬å¸ä»Šå¹´çš„é”€å”®ç›®æ ‡æ˜¯å¤šå°‘ï¼Ÿ")

    result = graph.invoke(
        {
            "messages": [HumanMessage(content="æˆ‘ä»¬å…¬å¸ä»Šå¹´çš„é”€å”®ç›®æ ‡æ˜¯å¤šå°‘ï¼Ÿ")],
            "needs_human_help": False,
            "human_response": ""
        },
        config=config
    )

    # æ£€æŸ¥æ˜¯å¦æœ‰ä¸­æ–­
    if "__interrupt__" in result and result["__interrupt__"]:
        print("\nğŸ“‹ AI è¯·æ±‚äººç±»ååŠ©:")
        interrupt_info = result["__interrupt__"][0]
        print(f"  é—®é¢˜: {interrupt_info.value['query']}")
        print(f"  è¯´æ˜: {interrupt_info.value['instructions']}")

        # æ¨¡æ‹Ÿäººç±»æä¾›ç­”æ¡ˆ
        print("\nğŸ‘¤ äººç±»å›å¤: ä»Šå¹´çš„é”€å”®ç›®æ ‡æ˜¯ 1000 ä¸‡å…ƒ")
        human_response = {"answer": "ä»Šå¹´çš„é”€å”®ç›®æ ‡æ˜¯ 1000 ä¸‡å…ƒï¼Œåˆ†å››ä¸ªå­£åº¦å®Œæˆã€‚"}

        # æ¢å¤æ‰§è¡Œ
        final_result = graph.invoke(Command(resume=human_response), config=config)

        # æ‰“å°æœ€ç»ˆå›å¤
        print("\nğŸ¤– AI æœ€ç»ˆå›å¤:")
        print(f"   {final_result['messages'][-1].content}")


# ============================================
# ç¤ºä¾‹ 5: é™æ€ä¸­æ–­ç‚¹æ¨¡å¼ (interrupt_before/after)
# ============================================
def example_5_static_breakpoints():
    """ä½¿ç”¨ç¼–è¯‘æ—¶è®¾ç½®çš„é™æ€ä¸­æ–­ç‚¹"""
    print("\n" + "=" * 60)
    print("ç¤ºä¾‹ 5: é™æ€ä¸­æ–­ç‚¹æ¨¡å¼ (interrupt_before/after)")
    print("=" * 60)

    class State(TypedDict):
        value: int
        history: Annotated[list[str], add]

    def step_a(state: State) -> dict:
        new_value = state["value"] + 10
        return {"value": new_value, "history": [f"Step A: {state['value']} -> {new_value}"]}

    def step_b(state: State) -> dict:
        new_value = state["value"] * 2
        return {"value": new_value, "history": [f"Step B: {state['value']} -> {new_value}"]}

    def step_c(state: State) -> dict:
        new_value = state["value"] - 5
        return {"value": new_value, "history": [f"Step C: {state['value']} -> {new_value}"]}

    # æ„å»ºå›¾
    builder = StateGraph(State)
    builder.add_node("step_a", step_a)
    builder.add_node("step_b", step_b)
    builder.add_node("step_c", step_c)

    builder.add_edge(START, "step_a")
    builder.add_edge("step_a", "step_b")
    builder.add_edge("step_b", "step_c")
    builder.add_edge("step_c", END)

    checkpointer = InMemorySaver()

    # ç¼–è¯‘æ—¶è®¾ç½®é™æ€ä¸­æ–­ç‚¹ï¼šåœ¨ step_b ä¹‹å‰ä¸­æ–­
    graph = builder.compile(
        checkpointer=checkpointer,
        interrupt_before=["step_b"]  # åœ¨ step_b æ‰§è¡Œå‰ä¸­æ–­
    )

    config = {"configurable": {"thread_id": str(uuid.uuid4())}}

    # ç¬¬ä¸€æ¬¡æ‰§è¡Œ - ä¼šåœ¨ step_b ä¹‹å‰åœæ­¢
    print("\nğŸš€ ç¬¬ä¸€æ¬¡æ‰§è¡Œï¼ˆä¼šåœ¨ step_b å‰åœæ­¢ï¼‰...")
    result1 = graph.invoke({"value": 5, "history": []}, config=config)
    print(f"   å½“å‰å€¼: {result1['value']}")
    print(f"   æ‰§è¡Œå†å²: {result1['history']}")

    # æ£€æŸ¥å½“å‰çŠ¶æ€
    print("\nâ¸ï¸ å›¾å·²åœ¨ step_b ä¹‹å‰æš‚åœ")
    print("   ç”¨æˆ·å¯ä»¥åœ¨æ­¤æ£€æŸ¥çŠ¶æ€å¹¶å†³å®šæ˜¯å¦ç»§ç»­...")

    # ç»§ç»­æ‰§è¡Œ - ä¼ å…¥ None è¡¨ç¤ºç»§ç»­
    print("\nâ–¶ï¸ ç»§ç»­æ‰§è¡Œ...")
    result2 = graph.invoke(None, config=config)
    print(f"   æœ€ç»ˆå€¼: {result2['value']}")
    print(f"   å®Œæ•´å†å²: {result2['history']}")


# ============================================
# ä¸»ç¨‹åº
# ============================================
if __name__ == "__main__":
    print("=" * 60)
    print("LangGraph Human In The Loop å®Œæ•´ç¤ºä¾‹")
    print("=" * 60)

    # è¿è¡Œæ‰€æœ‰ç¤ºä¾‹
    # example_1_basic_interrupt()
    example_2_content_review()
    # example_3_tool_approval()
    # example_4_chat_with_human_assistance()
    # example_5_static_breakpoints()

    print("\n" + "=" * 60)
    print("æ‰€æœ‰ç¤ºä¾‹æ‰§è¡Œå®Œæˆ!")
    print("=" * 60)
